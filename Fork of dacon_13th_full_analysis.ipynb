{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jeju BigData Competition - 퇴근시간 버스승차인원 예측\n\n## Notice\n* dacon_13회 분석 경진대회를 참여하여 최종 제출한 분석 인사이트 및 코드 정리\n* 최종 스코어 RMSE : 2.17\n* 등수 : private : 155등, public : 144등\n  - 먼저 분석 방법에 대해서 정리하고, 왜 점수가 낮은지도 한번 생각해보자\n\n\n## Contents\n* 분석 최종 코드 정리\n* 왜 점수가 낮았을까? 생각해보기\n* 이번 분석 경진대회를 통해 얻은 것들\n* 최종 결론\n\n### 분석 최종 코드 정리\n* 들어가기에 앞서, 크게 데이터 불러오기, 데이터 전처리, FE(Feature Engineering), 모델링 순으로 코드가 작성됨\n\n\n#### 데이터 불러오기\n* 해당 사이트에서 데이터를 다운로드 받을 수 있다 https://dacon.io/cpt13/228543\n* 다운로드 받은 후 데이터를 로딩하면, 한글이 깨져있음\n이런 경우에는 메모장으로 UTF-8로 저장한 후, 엑셀에서 메모장을 불러온 후 저장하고 로딩하면 정상적이게 불러 올 수 있음\n"},{"metadata":{},"cell_type":"markdown","source":"* 먼저 라이브러리와 path 설정을 해놓자."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library 호출\nrequire(dplyr);require(data.table);require(plotly)\nrequire(httr);require(dplyr);require(jsonlite);\nrequire(geosphere) # ggmap을 그리기 위한 library\nrequire(caret);require(dplyr);require(mlbench);require(e1071);require(data.table)\nrequire(klaR);require(pls);require(ipred);require(randomForest);require(sampling);require(glmnet)\nrequire(xgboost);require(randomForest);require(caret)\n\nlist.files(path = \"../input/dacon-14th/\")\npath.dir <- \"../input/dacon-14th/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data 간략 설명\n* 해당 링크를 참조하면 dataset에 설명을 참조할 수 있음\n* https://dacon.io/cpt13/235439"},{"metadata":{},"cell_type":"markdown","source":"### Data loading  \n* 기본적으로 read.csv function 보다 data.table package내 fread function 을 이용하면   \n  훨씬 더 빨리 데이터를 loading 할 수 있음"},{"metadata":{"trusted":true},"cell_type":"code","source":"train <- fread(paste0(path.dir, 'train.csv'), encoding = 'UTF-8')\ntest  <- fread(paste0(path.dir, 'test.csv'), encoding  = 'UTF-8')\ntest[,'train_test']  <- 'test'\ntrain[,'train_test'] <- 'train'\nfull.data <- data.frame(dplyr::bind_rows(train, test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1. id  \n* 데이터의 key가 되는 id column. 날짜별, 정류소별, 노선도별 key에 해당\n* 문자형으로 변환한다"},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data[,'id'] <- as.character(full.data[,'id'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. date\n* 날짜 컬럼\n* Date type으로 변환"},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data[,'date'] <- as.Date(full.data[,'date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. bus_route_id : 노선 ID\n* 노선ID, 마찬가지로 문자형으로 변환"},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data[,'bus_route_id'] <- as.character(full.data[,'bus_route_id'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. in_out : 시외버스, 시내버스로 구분\n* 1 시내   632939\n* 2 시외    10654\n* label encoding 진행"},{"metadata":{"trusted":true},"cell_type":"code","source":"in_out <- c('시외' = 2, '시내' = 1)\nfull.data$in_out <- as.integer(plyr::revalue(full.data$in_out, in_out))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. station_code : 해당 승하차 정류소의 ID\n* 마찬가지로 문자형으로 변환"},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data[,'station_code'] <- as.character(full.data[, 'station_code'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 파생변수 생성\n* 데이터 EDA를 통해 다양한 파생변수를 생성하였다.\n* 결과적으로 파생변수의 상관계수가 높지 않아 모델의 성능을 많이 높이지 못했다.\n* 개인적으로 영향인자일 것이라고 생각해서 기대를 많이 했지만 성능을 많이 높이지 못해서 아쉽다. 왜 그랬을까..?\n\n* 일단 어떤 파생변수를 생성했는지 알아보자"},{"metadata":{},"cell_type":"markdown","source":"#### 1. weekdays : 요일 변수\n* 아무래도 퇴근 시간 승차 인원은 주말에는 적게 타고, 평일에는 많이 탈 것이라고 생각했다. 따라서 요일 변수를 파생변수로 생성하여 추가하였다\n* label encoding을 진행하여 1~7이라는 숫자로 변경하였다"},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data[,'weekdays'] <- weekdays(full.data$date)\n\n# ## label encoding 수행\nweekdays_encoder <- c(  'Monday' = 1\n                        , 'Tuesday' = 2\n                        , 'Wednesday' = 3\n                        , 'Thursday' = 4\n                        , 'Friday' = 5\n                        , \"Saturday\" = 6\n                        , 'Sunday' = 7\n)\n\nfull.data$weekdays <- as.integer(plyr::revalue(full.data$weekdays, weekdays_encoder))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. holidays : 공휴일 변수\n* 마찬가지로 공휴일인 경우, 퇴근 시간 승차 인원에 영향을 미칠 것이라 생각하여 추가하였다\n* 기간자체가 길지 않으므로, hard coding해서 공휴일 변수를 추가하였다\n* label encoding을 통해 공휴일이면 '1', 아니면 '0'으로 변환하였다"},{"metadata":{"trusted":true},"cell_type":"code","source":"holidays <- as.Date(c('2019-09-01', '2019-09-07', '2019-09-08', '2019-09-12', '2019-09-13'\n                      , '2019-09-14', '2019-09-15', '2019-09-21', '2019-09-22', '2019-09-28'\n                      , '2019-09-29', '2019-10-03', '2019-10-05', '2019-10-06', '2019-10-09'\n                      , '2019-10-12', '2019-10-13', '2019-10-19', '2019-10-20', '2019-10-26', '2019-10-27'))\nfull.data <- full.data %>% mutate(holidays = ifelse(date %in% holidays, '1', '0'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. X6.8_ride ~ X10.12_takeoff\n* 종속변수가 6~8시(2시간) 승차인원을 예측해야 하므로, 독립변수의 기간도 2시간 간격으로 파생변수를 생성하였다"},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data <- full.data %>% mutate(\n  X6.8_ride       =  (X6.7_ride + X7.8_ride),\n  X8.10_ride      =  (X8.9_ride + X9.10_ride),\n  X10.12_ride     =  (X10.11_ride + X11.12_ride),\n  X6.8_takeoff    =  (X6.7_takeoff + X7.8_takeoff),\n  X8.10_takeoff   =  (X8.9_takeoff + X9.10_takeoff),\n  X10.12_takeoff  =  (X10.11_takeoff +  X11.12_takeoff)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. 버스정류소별 파생변수 생성\n* train/test 구분 없이 파생변수를 추가로 생성할 수 있게끔 하는 변수는 버스 정류소라고 판단하였다.\n* 따라서 버스정류소별로 추가적인 외부 데이터를 생성하거나 기존 변수들을 활용하여 파생변수를 생성하였다."},{"metadata":{},"cell_type":"markdown","source":"##### KaKaoMap API 활용\n변수명 : hospital, bank, school, academy, culture, food, cafe, building, apartment \n* 우선적으로 버스 정류소 100m 근방에 병원,은행,학교,학원 등 주요 시설의 개수가 많을수록 6~8시 승차 인원이 많을 수 있을것이라 판단하여 추가하였다.\n* 결과적으로 상관계수를 확인해 보았는데, 상관도는 매우 낮아 최종 모델링 독립 변수에는 추가하지 않았다.\n\n변수명 : town_name\n* 해당 좌표가 포함되는 '동'을 파생변수로 추가하였다"},{"metadata":{},"cell_type":"markdown","source":"##### 중급 코드 변수 활용\n변수명 : dis_jeju,\tdis_gosan,\tdis_sungsan,\tdis_seoguipo,\tarea_name\n* 데이콘에 업로드되어 올라와있는 중급 코드 내용을 활용하였다\n* 제주, 고산, 성상, 서귀포시의 관측소 위도, 경도를 기준으로 거리를 계산하여 파생변수로 추가하였다"},{"metadata":{"trusted":true},"cell_type":"code","source":"load( \"../input/dacon-13th-busstation/BusStation.RData\")\nhead(BusStation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KAKAO_KEYWORD           <-  c('병원', '은행', '학교', '학원', '문화시설' ,'음식점' ,'카페', '빌딩', '아파트')\nnames(KAKAO_KEYWORD) <-  c('hospital', 'bank', 'school', 'academy', 'culture', 'food', 'cafe', 'building', 'apartment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BusStation    <- BusStation %>%  select_at(c('station_code', 'city_name'\n                                             , 'town_name', 'address_no',  names(KAKAO_KEYWORD), 'dis_jeju', 'dis_gosan', 'dis_sungsan', 'dis_seoguipo', 'area_name'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### town_name Label encoding\n* town_name의  범주형 변수를 우선적으로 label encoding을 진행한다.\n* 결과적으로 쓰지 못했는데, 그 이유는 class 자체가 180개가 넘는 label class가 존재하고, 수행시간이 너무 오래걸려 제외하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# town_name encoding\ntownName_uni <- BusStation %>% group_by(town_name) %>% dplyr::summarise(n = n()) %>% arrange(n) %>%  dplyr::select(town_name)\ntownName_uni <- townName_uni %>% mutate(label = seq(1:nrow(townName_uni))) %>% data.frame()\ntown_name_encoder        <- townName_uni[,'label']\nnames(town_name_encoder) <- townName_uni[,'town_name']\nBusStation$town_name     <- as.factor(plyr::revalue(BusStation$town_name, town_name_encoder))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 기존의 train/test dataset에 해당 파생변수를 추가한다 \nfull.data  <- dplyr::inner_join(full.data, BusStation, by = 'station_code')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 범주형 처리\nfull.data[,'weekdays'] <- as.factor(full.data[,'weekdays'])\nfull.data[,'holidays'] <- as.factor(full.data[,'holidays'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 일별 정류소별 버스 운행 대수 추가\n변수명 : bus_vhc\n* 기존 버스 카드 데이터를 이용하여 해당 버스 정류소의 버스 운행 대수를 추가하여 편성하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"###### 일별 정류소별 버스 운행 대수 추가 #########\ng_station <- fread('../input/dacon-13th-vhc/data_bus_vhc.csv', encoding = 'UTF-8')\ng_station$date         <- as.Date(g_station$date)\ng_station$station_code <- as.character(g_station$station_code)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data <- dplyr::left_join(full.data, g_station, by = c(\"date\" = \"date\", \"station_code\" = \"station_code\"))\nfull.data[,'vhc_id'] <- ifelse(is.na(full.data[,'vhc_id']), 0, full.data[,'vhc_id'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 정류소별 평균, 분산 통계량 확인\n* 정류소별 평균과 분산 통계량을 확인하였다.\n* 만약 종속변수(X18~20.ride)의 평균,분산 값이 0이라면 해당 정류소에는 test Dataset 종속변수 값도 0으로 판단할 수 있다.(모델은 그렇게 판단하지 않을 수 있으므로..)\n* 따라서 해당 작업을 수행하도록 한다"},{"metadata":{"trusted":true},"cell_type":"code","source":"YvalueByStation  <- full.data  %>% filter(train_test == 'train')  %>%  group_by(station_code)  %>% dplyr::summarise(\n    MEAN = mean(X18.20_ride, na.rm = T),\n    VAR  = var(X18.20_ride)\n)\nYvalueByStation[which(is.na(YvalueByStation$VAR)), 'VAR'] <- 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"station_zero   <- YvalueByStation  %>% filter(MEAN == 0)  %>%  dplyr::select(station_code)  %>%  unlist  %>%  unname","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_zero      <-  full.data   %>% filter(train_test == 'test' & station_code %in% station_zero)  %>% dplyr::select(id)  %>%  unlist  %>%  unname\nfull.data.test <-  full.data   %>% filter(!(station_code %in% station_zero))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. one-hot encoding 수행\n* full.data 내에서는 범주형 데이터가 존재한다. 따라서 one-hot encoding을 우선적으로 수행하자\n* 변환할 변수 : weekdays, city_name"},{"metadata":{"trusted":true},"cell_type":"code","source":"one.hot.weekdays     <- model.matrix(~weekdays, data = full.data.test)[ , -1]\none.hot.city_name    <- model.matrix(~city_name, data = full.data.test)[ , -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data_oneHotEncoding <- cbind(full.data.test, one.hot.weekdays)\nfull.data_oneHotEncoding <- cbind(full.data_oneHotEncoding, one.hot.city_name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. K-means를 통한 군집 생성\n* 처음에는 고산, 성산, 제주, 서귀포 관측소 좌표를 기준으로 가까운 곳을 군집으로 하여 계산하였는데, 이는 종속변수를 고려하지 않은 구분이라고 판단하였다.\n* 시각화를 수행해보면 물론 서귀포, 제주시에 많은 정류소와 비교적 높은 비율의 종속변수 값을 확인할 수 있지만,\n* 이러한 방법이 더 좋은 성능을 가져다 줄 것이라 생각하여 군집을 추가하고, 군집별로 모델을 생성하였다. 군집기준은 정류소로 하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"YvalueByStation_NonZero <- YvalueByStation  %>% filter(MEAN != 0)\nM.CLUST                 <- kmeans(YvalueByStation_NonZero[,-1], 5, nstart = 1000)\nYvalueByStation_NonZero['K_M'] <- M.CLUST$cluster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full.data_oneHotEncoding   <- dplyr::left_join(full.data_oneHotEncoding, YvalueByStation_NonZero[,c('station_code', 'K_M')])\nfull.data_oneHotEncoding  <- full.data_oneHotEncoding %>% mutate(K_M = ifelse(is.na(K_M),  which.max(M.CLUST$size), K_M))\nfull.data_oneHotEncoding_1 <- full.data_oneHotEncoding  %>% filter(K_M == 1)  \nfull.data_oneHotEncoding_2 <- full.data_oneHotEncoding  %>% filter(K_M == 2) \nfull.data_oneHotEncoding_3 <- full.data_oneHotEncoding  %>% filter(K_M == 3)  \nfull.data_oneHotEncoding_4 <- full.data_oneHotEncoding  %>% filter(K_M == 4)  \nfull.data_oneHotEncoding_5 <- full.data_oneHotEncoding  %>% filter(K_M == 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7.train/test 분리, shuffling 진행\n* train, test별로 다시 분리하고, 혹시 날짜별로 나열되어있는 경우를 생각해 shuffling을 진행하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train / test 별로 data 분할(여기서 test 는 실제 맞춰야할 test data)\n# 평가를 위한 test data는 생성 x\ntraining_1 <- full.data_oneHotEncoding_1  %>%  filter(train_test == 'train')\ntesting_1  <- full.data_oneHotEncoding_1  %>%  filter(train_test == 'test')\n\ntraining_2 <- full.data_oneHotEncoding_2  %>%  filter(train_test == 'train')\ntesting_2  <- full.data_oneHotEncoding_2  %>%  filter(train_test == 'test')\n\ntraining_3 <- full.data_oneHotEncoding_3  %>%  filter(train_test == 'train')\ntesting_3  <- full.data_oneHotEncoding_3  %>%  filter(train_test == 'test')\n\ntraining_4 <- full.data_oneHotEncoding_4  %>%  filter(train_test == 'train')\ntesting_4  <- full.data_oneHotEncoding_4  %>%  filter(train_test == 'test')\n\ntraining_5 <- full.data_oneHotEncoding_5  %>%  filter(train_test == 'train')\ntesting_5  <- full.data_oneHotEncoding_5  %>%  filter(train_test == 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set.seed(100)\ntraining_1 <- training_1[sample(1:nrow(training_1)), ]\ntesting_1  <- testing_1[sample(1:nrow(testing_1)),   ]\n\ntraining_2 <- training_2[sample(1:nrow(training_2)), ]\ntesting_2  <- testing_2[sample(1:nrow(testing_2)),   ]\n\ntraining_3 <- training_3[sample(1:nrow(training_3)), ]\ntesting_3  <- testing_3[sample(1:nrow(testing_3)),   ]\n\ntraining_4 <- training_4[sample(1:nrow(training_4)), ]\ntesting_4  <- testing_4[sample(1:nrow(testing_4)),   ]\n\ntraining_5 <- training_5[sample(1:nrow(training_5)), ]\ntesting_5  <- testing_5[sample(1:nrow(testing_5)),   ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8. X, Y 편성\n* Xvar, Yvar를 편성한다.\n* 일반적으로 혐의인자탐지를 통해 독립변수의 중요로를 생각하여 setting하는 것이 일반적이다.\n* 혐의인자탐지는 생략하였으나, 결과적으로 모든 변수를 추가하는 것이 좋다고 판단하여 필요한 변수들은 모두 추가하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"Yvar    <- c('X18.20_ride')\nXvar    <- c(      'in_out'\n                 ,  'latitude'\n                 , 'longitude'\n                 , 'weekdays2'          \n                  , 'weekdays3'          \n                  , 'weekdays4'          \n                  , 'weekdays5'  \n                  , 'weekdays6'          \n                  , 'weekdays7'          \n                  , 'holidays'           # 범주\n                  , 'X6.8_ride'\n                  , 'X8.10_ride'\n                  , 'X10.12_ride'\n                  , 'X6.8_takeoff'\n                  , 'X8.10_takeoff'\n                  , 'X10.12_takeoff'\n                  , 'city_name1'\n                  , 'city_name2'\n                  , 'city_name'         # 범주\n                  , 'town_name'         # 범주\n                  , 'hospital'\n                 , 'bank'\n                 , 'school'\n                 , 'academy'\n                 , 'culture'\n                 , 'food'\n                 , 'cafe'\n                 , 'building'\n                 , 'apartment'\n                 , 'dis_jeju'\n                 , 'dis_gosan'\n                 , 'dis_sungsan'\n                 , 'dis_seoguipo'\n                 , 'vhc_id')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fmle         <- formula(paste0(Yvar, \" ~ \", paste(paste(Xvar, collapse =' + '))))\nfmle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9. XGBoost 수행\n* 최종 모델은 XGBoost를 생성하였다.\n* 해당 모델은 randomforest에 비해 성능이 빠르다고 알려져 있는 Boosting 앙상블 모델 중 하나이다."},{"metadata":{},"cell_type":"markdown","source":"#### hyper parameter setting\n* 먼저 hyper parameter를 setting 하였다.\n* hyper parameter의 의미는 주석을 달아두었다."},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbGrid <- expand.grid(nrounds = c(100,200),                               # boosting round를 결정. 랜덤하게 생성되는 모델이니 만큼 이 수가 적당히 큰 게 좋음. epoch 옵션과 동일.                                \n                       max_depth = c(10, 15, 20),                          # 한 트리의 maximum depth. 숫자를 키울수록 모델의 복잡도는 커짐. 과적합 하기 쉬움. 디폴트는 6.이때 리프 노드의 개수는 최대 64\n                       colsample_bytree = seq(0.5, 0.9, length.out = 3),   # 나무를 생성할 때  샘플링하는 열의 비율\n                       eta = seq(0.1, 0.5, length.out = 8),                # learning rate, 트리에 가지가 많을수록 과적합 되기 쉬움.\n                       gamma = 0                                           # information gain에서 -r로 표현한바 있음. 이것이 커지면 트리 깊이가 줄어들어 보수적인 모델이 됨\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### cross-validation 수행\n* 반복 횟수와 k-fold에서의 k 값을 setting 하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# cv_k   : k-fold에서의 k\n# cv_rep : 반복횟수 \ncv_k   = 3\ncv_rep = 2\nfitControl <- trainControl(method    = \"repeatedcv\"\n                           , number  = cv_k)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 생성\n* 최종적으로 군집을 4개 만들었는데, 군집별로 XGBoost를 각각 생성하였다.\n* package는 caret package를 사용하였다."},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model_1 = train(\n  f         =  fmle,\n  data      =  training_1,\n  trControl =  fitControl,\n  method    =  \"xgbLinear\"\n)\nxgb_model_1[['results']]  %>% arrange(RMSE)  %>% head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model_2 = train(\n  f         =  fmle,\n  data      =  training_2,\n  trControl =  fitControl,\n  method    =  \"xgbLinear\"\n)\nxgb_model_2[['results']]  %>% arrange(RMSE) %>% head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model_3 = train(\n  f         =  fmle,\n  data      =  training_3,\n  trControl =  fitControl,\n  method    =  \"xgbLinear\"\n)\nxgb_model_3[['results']]  %>% arrange(RMSE)  %>%  head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model_4 = train(\n  f         =  fmle,\n  data      =  training_4,\n  trControl =  fitControl,\n  method    =  \"xgbLinear\"\n)\nxgb_model_4[['results']]  %>% arrange(RMSE)  %>%  head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model_5 = train(\n  f         =  fmle,\n  data      =  training_5,\n  trControl =  fitControl,\n  method    =  \"xgbLinear\"\n)\nxgb_model_5[['results']]  %>% arrange(RMSE)  %>% head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save(xgb_model_1, file = paste0('Xvar_V22_1_',Sys.Date(), '_',cv_k, '_', cv_rep,'.RData')) # glmnet 모델 저장\nsave(xgb_model_2, file = paste0('Xvar_V22_2_',Sys.Date(), '_',cv_k, '_', cv_rep,'.RData')) # glmnet 모델 저장\nsave(xgb_model_3, file = paste0('Xvar_V22_3_',Sys.Date(), '_',cv_k, '_', cv_rep,'.RData')) # glmnet 모델 저장\nsave(xgb_model_4, file = paste0('Xvar_V22_4_',Sys.Date(), '_',cv_k, '_', cv_rep,'.RData')) # glmnet 모델 저장\nsave(xgb_model_5, file = paste0('Xvar_V22_5_',Sys.Date(), '_',cv_k, '_', cv_rep,'.RData')) # glmnet 모델 저장","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_1           <- predict(xgb_model_1, testing_1)\npredicted_1           <- ifelse(predicted_1 < 0, 0, predicted_1)\ntesting_1$X18.20_ride <- predicted_1\npredicted_2           <- predict(xgb_model_2, testing_2)\npredicted_2           <- ifelse(predicted_2 < 0, 0, predicted_2)\ntesting_2$X18.20_ride <- predicted_2\npredicted_3           <- predict(xgb_model_3, testing_3)\npredicted_3           <- ifelse(predicted_3 < 0, 0, predicted_3)\ntesting_3$X18.20_ride <- predicted_3\npredicted_4           <- predict(xgb_model_4, testing_4)\npredicted_4           <- ifelse(predicted_4 < 0, 0, predicted_4)\ntesting_4$X18.20_ride <- predicted_4\npredicted_5           <- predict(xgb_model_5, testing_5)\npredicted_5           <- ifelse(predicted_5 < 0, 0, predicted_5)\ntesting_5$X18.20_ride <- predicted_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData <- dplyr::bind_rows(testing_1, testing_2)\ntestData <- dplyr::bind_rows(testData, testing_3)\ntestData <- dplyr::bind_rows(testData, testing_4)\ntestData <- dplyr::bind_rows(testData, testing_5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data           <- testData[,c('id', 'X18.20_ride')]\nsubmission_data           <- dplyr::bind_rows(submission_data, data.frame(id =test_zero, X18.20_ride = 0, stringsAsFactors = F))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colnames(submission_data) <- c('id', '18~20_ride')\nsubmission_data <- submission_data %>%  arrange(id) %>% data.frame()\nsave(submission_data, file ='submission_data.RData')\nwrite.csv(submission_data, 'submission_data.csv', fileEncoding = 'UTF-8', row.names = F)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}